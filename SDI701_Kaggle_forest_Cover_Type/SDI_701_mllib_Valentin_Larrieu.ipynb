{"cells":[{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.tuning import ParamGridBuilder,CrossValidator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier                              \nfrom pyspark.ml.regression import DecisionTreeRegressor,RandomForestRegressor\nfrom pyspark.sql import SQLContext\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn import model_selection\nfrom sklearn import metrics\nimport pandas as pd"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# Please look at the report for more details.\n# My way to do this competition was to test different models, improve them then select the best one and try to pefect it.\n# I tried some feature selection and cleaning. For instance rebalancing the dataset since all the cover type are not equaly balanced, but it did not iprove the score. I suppose its a bias linked with how\n# The cover type are balanded also in the test set (some cover have 10 times more datapoints than others).\n# After trying the logistic regression model i implemented a cross validation to optimise parameters. I saw that the result could be improved so i tried other algorithms.\n# I used random forest then decision tree. This one gave me the best result (regarding to the limit of databricks) on Mllib.\n# In order to improve my score i then tried some of the model of sklearn. The best result I found were with the extraTree algorithm. I reached a score of 0.95967 on kaggle with it (code of model 3 in the file \"SDI_701_sklearn_Valentin_Larrieu\").\n# Databricks limited me on the number of estimator (too much ressources needed), so i trained my model locally on my PC to slightly improve the results (to gain some .0001%).\n#\n# You will find in this notebook the code :\n#      -[Model 1] The best Model I could build with Mllib (A Decision Tree with cross validation)\n#      -[Model 2] The best Model I could build with sklearn (An Extratree) on Databricks before the improvment i did locally\n#  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# We fix the seed\nSEED = 1234"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["# We import the data\ndf_train = spark.read.  \\\n         option(\"header\", \"true\"). \\\n         option(\"nullValue\", \"?\"). \\\n         option(\"inferSchema\", \"true\"). \\\n         option(\"sep\", \",\"). \\\n         csv(\"/FileStore/tables/train_set-51e11.csv\") \n\ndf_test = spark.read.  \\\n         option(\"header\", \"true\"). \\\n         option(\"nullValue\", \"?\"). \\\n         option(\"inferSchema\", \"true\"). \\\n         option(\"sep\", \",\"). \\\n         csv(\"/FileStore/tables/test_set-b5f57.csv\") \n\n# We split it according to the split giving us the best results (90% / 10%)\ntrainData, testData = df_train.randomSplit([0.90,0.10],seed=SEED)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# We control the size of our elements\nprint('Train data size: {} rows, {} columns'.format(df_train.count(), len(df_train.columns)))\nprint('Test data size: {} rows, {} columns'.format(df_test.count(), len(df_test.columns)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Train data size: 528720 rows, 56 columns\nTest data size: 226595 rows, 55 columns\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["vector_assembler = VectorAssembler(inputCols=[\"Elevation\", \"Aspect\", \"Slope\", \"Horizontal_Distance_To_Hydrology\", \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\", \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\", \"Horizontal_Distance_To_Fire_Points\", \"Wilderness_Area1\", \"Wilderness_Area2\", \"Wilderness_Area3\", \"Wilderness_Area4\", \"Soil_Type1\", \"Soil_Type2\", \"Soil_Type3\", \"Soil_Type4\", \"Soil_Type5\", \"Soil_Type6\", \"Soil_Type7\", \"Soil_Type8\", \"Soil_Type9\", \"Soil_Type10\", \"Soil_Type11\", \"Soil_Type12\", \"Soil_Type13\", \"Soil_Type14\", \"Soil_Type15\", \"Soil_Type16\", \"Soil_Type17\", \"Soil_Type18\", \"Soil_Type19\", \"Soil_Type20\", \"Soil_Type21\", \"Soil_Type22\", \"Soil_Type23\", \"Soil_Type24\", \"Soil_Type25\", \"Soil_Type26\", \"Soil_Type27\", \"Soil_Type28\", \"Soil_Type29\", \"Soil_Type30\", \"Soil_Type31\", \"Soil_Type32\", \"Soil_Type33\", \"Soil_Type34\", \"Soil_Type35\", \"Soil_Type36\", \"Soil_Type37\", \"Soil_Type38\", \"Soil_Type39\", \"Soil_Type40\"], outputCol=\"features\")\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["############# Model 1 Cross validation and decision tree\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"Cover_Type\", featuresCol=\"features\", cacheNodeIds=True)\n\n# We create our evaluator\nevaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\", predictionCol=\"prediction\", metricName=\"f1\")\n\n# We set the parameters we want to try\nparamGridDt = ParamGridBuilder().\\\n            addGrid(dt.maxDepth, [30]).\\\n            addGrid(dt.maxBins, [200]).\\\n            addGrid(dt.impurity, [\"entropy\"]).\\\n            addGrid(dt.minInstancesPerNode, [3]).\\\n            build()\n# Here there is no different choice for each parameter, that is because we optimised the different param\n\n# We set the pipeline\npipelineDt = Pipeline(stages=[vector_assembler, dt])\n\n#Create 5-fold CrossValidator\ncv3 = CrossValidator(estimator=pipelineDt, estimatorParamMaps=paramGridDt, evaluator=evaluator, numFolds=5)\n\n#Fit cross-validation model\ncvModel3 = cv3.fit(trainData)\n\n#Use test set to measure the accuracy of our model on new data\n#Prediction\npred_training_cv3 = cvModel3.transform(trainData)\npred_test_cv3 = cvModel3.transform(testData) #test\n\n#Evaluation\n# performance on training data\nprint(\"Train data performance Decision Tree = \", evaluator.evaluate(pred_training_cv3))\n\n# performance on test data\nprint(\"Test data performance Decision Tree = \", evaluator.evaluate(pred_test_cv3))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&apos;Train data performance Decision Tree = &apos;, 0.9763744425137119)\n(&apos;Test data performance Decision Tree = &apos;, 0.9071774741199612)\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# We export our best model to submit it on kaggle\nmodel = cvModel3\n\n# Make predictions on testData\npredictions = model.transform(df_test) \n\n\npredictions = predictions.withColumn(\"Cover_Type\", predictions[\"prediction\"].cast(\"int\")) \n\n# Select columns Id and prediction\n(predictions\n .repartition(1)\n .select('Id', 'Cover_Type')\n .write\n .format('com.databricks.spark.csv')\n .options(header='true')\n .mode('overwrite')\n .save('/FileStore/kaggle-submission'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["# We display the path of the file\ndisplay(dbutils.fs.ls(\"dbfs:/FileStore/kaggle-submission\"))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/FileStore/kaggle-submission/_SUCCESS</td><td>_SUCCESS</td><td>0</td></tr><tr><td>dbfs:/FileStore/kaggle-submission/_committed_5702443627356436892</td><td>_committed_5702443627356436892</td><td>199</td></tr><tr><td>dbfs:/FileStore/kaggle-submission/_committed_5868879643784577909</td><td>_committed_5868879643784577909</td><td>199</td></tr><tr><td>dbfs:/FileStore/kaggle-submission/_committed_9174243400005013254</td><td>_committed_9174243400005013254</td><td>199</td></tr><tr><td>dbfs:/FileStore/kaggle-submission/_committed_vacuum4319346291273316749</td><td>_committed_vacuum4319346291273316749</td><td>129</td></tr><tr><td>dbfs:/FileStore/kaggle-submission/_started_9174243400005013254</td><td>_started_9174243400005013254</td><td>0</td></tr><tr><td>dbfs:/FileStore/kaggle-submission/part-00000-tid-9174243400005013254-7650f166-2638-4abb-a192-5506563ab2e5-3896-c000.csv</td><td>part-00000-tid-9174243400005013254-7650f166-2638-4abb-a192-5506563ab2e5-3896-c000.csv</td><td>2039369</td></tr></tbody></table></div>"]}}],"execution_count":9},{"cell_type":"code","source":["## Model 2 : ExtraTrees with Sklearn\n\n# We need pandas dataframe for sklearn\ndf_train2 = df_train.toPandas()\ndf_test2 = df_test.toPandas()\n\nY = df_train2.Cover_Type\n# We drop the ID column because it do not give usefull information\nX = df_train2.drop(['Id','Cover_Type'],axis=1)\nX_test_input = df_test2.drop('Id',axis=1)\n\n# We split our data\nX_train,X_test,Y_train,Y_test = model_selection.train_test_split(X,Y,test_size=0.1)\n\n# We set our ExtraTrees model with parameters we optimised\net = ExtraTreesClassifier(n_estimators=200, criterion= 'entropy')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["# We fit our model\net.fit(X_train,Y_train)\n\n# We use it to predict our output\nY_hat = et.predict(X_test)\n\n# We print the results\nprint(metrics.classification_report(Y_test,Y_hat))\nprint(\"ExtraTrees Accuracy :\", metrics.accuracy_score(Y_test,Y_hat))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">             precision    recall  f1-score   support\n\n          1       0.96      0.93      0.94     19162\n          2       0.94      0.97      0.95     25714\n          3       0.93      0.96      0.95      3393\n          4       0.93      0.86      0.90       258\n          5       0.93      0.74      0.83       896\n          6       0.92      0.87      0.89      1574\n          7       0.97      0.94      0.95      1875\n\navg / total       0.94      0.94      0.94     52872\n\n(&apos;ExtraTrees Accuracy :&apos;, 0.94445074897866543)\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["# We retrain our model with our entire set to have the best model for kaggle\net2 = ExtraTreesClassifier(n_estimators=200, criterion= 'entropy')\net2.fit(X,Y)\nY_hat_export = et2.predict(X_test_input)\n\nexport_df = pd.DataFrame({'Id':df_test2.Id.values,'Cover_Type':Y_hat_export}).sort_index(ascending=False,axis=1)\ndf_export_2 = sqlContext.createDataFrame(export_df)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\nError while obtaining a new communication channel"]}}],"execution_count":12},{"cell_type":"code","source":["(df_export_2\n .repartition(1)\n .select('Id', 'Cover_Type')\n .write\n .format('com.databricks.spark.csv')\n .options(header='true')\n .mode('overwrite')\n .save('/FileStore/kaggle-submission2'))"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# We display the path of the file\ndisplay(dbutils.fs.ls(\"dbfs:/FileStore/kaggle-submission2\"))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["## Model 3 Local : ExtraTrees with Sklearn => loook at the file \"SDI_701_sklearn_Valentin_Larrieu\"\n"],"metadata":{},"outputs":[],"execution_count":15}],"metadata":{"name":"Kaggle_Larrieu_SD701_Rendu","notebookId":705710625259203},"nbformat":4,"nbformat_minor":0}
